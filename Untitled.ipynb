{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore train data\n",
    "\n",
    "You will work with another Kaggle competition called \"Store Item Demand Forecasting Challenge\". In this competition, you are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items in 10 different stores.\n",
    "\n",
    "To begin, let's explore the train data for this competition. For the faster performance, you will work with a subset of the train data containing only a single month history.\n",
    "\n",
    "Your initial goal is to read the input data and take the first look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (913000, 4)\n",
      "         date  store  item  sales\n",
      "0  2013-01-01      1     1     13\n",
      "1  2013-01-02      1     1     11\n",
      "2  2013-01-03      1     1     14\n",
      "3  2013-01-04      1     1     13\n",
      "4  2013-01-05      1     1     10\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read train data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Look at the shape of the data\n",
    "print('Train shape:', train.shape)\n",
    "\n",
    "# Look at the head() of the data\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore test data\n",
    "\n",
    "Having looked at the train data, let's explore the test data in the \"Store Item Demand Forecasting Challenge\". Remember, that the test dataset generally contains one column less than the train one.\n",
    "\n",
    "This column, together with the output format, is presented in the sample submission file. Before making any progress in the competition, you should get familiar with the expected output.\n",
    "\n",
    "That is why, let's look at the columns of the test dataset and compare it to the train columns. Additionally, let's explore the format of the sample submission. The train DataFrame is available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['date', 'store', 'item', 'sales']\n",
      "Test columns: ['id', 'date', 'store', 'item']\n",
      "   id  sales\n",
      "0   0     52\n",
      "1   1     52\n",
      "2   2     52\n",
      "3   3     52\n",
      "4   4     52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the test data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "# Print train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())\n",
    "\n",
    "# Read the sample submission file\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# Look at the head() of the sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple model\n",
    "\n",
    "As you determined, you are dealing with a regression problem. So, now you're ready to build a model for a subsequent submission. But now, instead of building the simplest Linear Regression model as in the slides, let's build an out-of-box Random Forest model.\n",
    "\n",
    "You will use the RandomForestRegressor class from the scikit-learn library.\n",
    "\n",
    "Your objective is to train a Random Forest model with default parameters on the \"store\" and \"item\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Read the train data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Create a Random Forest object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Train a model\n",
    "rf.fit(X=train[['store', 'item']], y=train['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a submission\n",
    "\n",
    "You've already built a model on the training data from the Kaggle Store Item Demand Forecasting Challenge. Now, it's time to make predictions on the test data and create a submission file in the specified format.\n",
    "\n",
    "Your goal is to read the test data, make predictions, and save these in the format specified in the \"sample_submission.csv\" file. The rf object you created in the previous exercise is available in your workspace.\n",
    "\n",
    "Note that starting from now and for the rest of the course, pandas library will be always imported for you and could be accessed as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  sales\n",
      "0   0     52\n",
      "1   1     52\n",
      "2   2     52\n",
      "3   3     52\n",
      "4   4     52\n"
     ]
    }
   ],
   "source": [
    "# Read test and sample submission data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# Show the head() of the sample_submission\n",
    "print(sample_submission.head())\n",
    "\n",
    "# Get predictions for the test set\n",
    "test['sales'] = rf.predict(test[['store', 'item']])\n",
    "\n",
    "# Write test predictions using the sample_submission format\n",
    "test[['id', 'sales']].to_csv('kaggle_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost models\n",
    "\n",
    "Every Machine Learning method could potentially overfit. You will see it on this example with XGBoost. Again, you are working with the Store Item Demand Forecasting Challenge. The train DataFrame is available in your workspace.\n",
    "\n",
    "Firstly, let's train multiple XGBoost models with different sets of hyperparameters using XGBoost's learning API. The single hyperparameter you will change is:\n",
    "\n",
    "max_depth - maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 2,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_2 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 8,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_8 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 15,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_15 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore overfitting XGBoost\n",
    "\n",
    "Having trained 3 XGBoost models with different maximum depths, you will now evaluate their quality. For this purpose, you will measure the quality of each model on both the train data and the test data. As you know by now, the train data is the data models have been trained on. The test data is the next month sales data that models have never seen before.\n",
    "\n",
    "The goal of this exercise is to determine whether any of the models trained is overfitting. To measure the quality of the models you will use Mean Squared Error (MSE). It's available in sklearn.metrics as mean_squared_error() function that takes two arguments: true values and predicted values.\n",
    "\n",
    "train and test DataFrames together with 3 models trained (xg_depth_2, xg_depth_8, xg_depth_15) are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 607.487. MSE Test: 355.254\n",
      "MSE Train: 294.466. MSE Test: 42.633\n",
      "MSE Train: 255.334. MSE Test: 3.645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']])\n",
    "dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "\n",
    "# For each of 3 trained models\n",
    "for model in [xg_depth_2, xg_depth_8, xg_depth_15]:\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(dtrain)     \n",
    "    test_pred = model.predict(dtest)          \n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_train = mean_squared_error(train['sales'], train_pred)                  \n",
    "    mse_test = mean_squared_error(test['sales'], test_pred)\n",
    "    print('MSE Train: {:.3f}. MSE Test: {:.3f}'.format(mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a competition metric\n",
    "\n",
    "Competition metric is used by Kaggle to evaluate your submissions. Moreover, you also need to measure the performance of different models on a local validation set.\n",
    "\n",
    "For now, your goal is to manually develop a couple of competition metrics in case if they are not available in sklearn.metrics.\n",
    "\n",
    "In particular, you will define:\n",
    "\n",
    "Mean Squared Error (MSE) for the regression problem:\n",
    "\n",
    "MSE=1N∑i=1N(yi−y^i)2\n",
    "\n",
    "Logarithmic Loss (LogLoss) for the binary classification problem:\n",
    "\n",
    "LogLoss=−1N∑i=1N(yilnpi+(1−yi)ln(1−pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn MSE: 0.15418. \n",
      "Your MSE: 0.15418. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import MSE from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define your own MSE function\n",
    "def own_mse(y_true, y_pred):\n",
    "  \t# Raise differences to the power of 2\n",
    "    squares = np.power(y_true - y_pred, 2)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(squares)\n",
    "    return err\n",
    "\n",
    "y_regression_true = np.array([0.69646919,0.28613933,0.22685145,0.55131477,0.71946897,0.42310646,\n",
    "0.9807642,0.68482974,0.4809319,0.39211752,0.34317802,0.72904971,\n",
    "0.43857224,0.0596779,0.39804426,0.73799541,0.18249173,0.17545176,\n",
    "0.53155137,0.53182759,0.63440096,0.84943179,0.72445532,0.61102351,\n",
    "0.72244338,0.32295891,0.36178866,0.22826323,0.29371405,0.63097612,\n",
    "0.09210494,0.43370117,0.43086276,0.4936851,0.42583029,0.31226122,\n",
    "0.42635131,0.89338916,0.94416002,0.50183668,0.62395295,0.1156184,\n",
    "0.31728548,0.41482621,0.86630916,0.25045537,0.48303426,0.98555979,\n",
    "0.51948512,0.61289453,0.12062867,0.8263408,0.60306013,0.54506801,\n",
    "0.34276383,0.30412079,0.41702221,0.68130077,0.87545684,0.51042234,\n",
    "0.66931378,0.58593655,0.6249035,0.67468905,0.84234244,0.08319499,\n",
    "0.76368284,0.24366637,0.19422296,0.57245696,0.09571252,0.88532683,\n",
    "0.62724897,0.72341636,0.01612921,0.59443188,0.55678519,0.15895964,\n",
    "0.15307052,0.69552953,0.31876643,0.6919703,0.55438325,0.38895057,\n",
    "0.92513249,0.84167,0.35739757,0.04359146,0.30476807,0.39818568,\n",
    "0.70495883,0.99535848,0.35591487,0.76254781,0.59317692,0.6917018,\n",
    "0.15112745,0.39887629,0.2408559,0.34345601])\n",
    "\n",
    "y_regression_pred = np.array([0.51312815,0.66662455,0.10590849,0.13089495,0.32198061,0.66156434,\n",
    "0.84650623,0.55325734,0.85445249,0.38483781,0.3167879,0.35426468,\n",
    "0.17108183,0.82911263,0.33867085,0.55237008,0.57855147,0.52153306,\n",
    "0.00268806,0.98834542,0.90534158,0.20763586,0.29248941,0.52001015,\n",
    "0.90191137,0.98363088,0.25754206,0.56435904,0.80696868,0.39437005,\n",
    "0.73107304,0.16106901,0.60069857,0.86586446,0.98352161,0.07936579,\n",
    "0.42834727,0.20454286,0.45063649,0.54776357,0.09332671,0.29686078,\n",
    "0.92758424,0.56900373,0.457412,0.75352599,0.74186215,0.04857903,\n",
    "0.7086974,0.83924335,0.16593788,0.78099794,0.28653662,0.30646975,\n",
    "0.66526147,0.11139217,0.66487245,0.88785679,0.69631127,0.44032788,\n",
    "0.43821438,0.7650961,0.565642,0.08490416,0.58267109,0.8148437,\n",
    "0.33706638,0.92757658,0.750717,0.57406383,0.75164399,0.07914896,\n",
    "0.85938908,0.82150411,0.90987166,0.1286312,0.08178009,0.13841557,\n",
    "0.39937871,0.42430686,0.56221838,0.12224355,0.2013995,0.81164435,\n",
    "0.46798757,0.80793821,0.00742638,0.55159273,0.93193215,0.58217546,\n",
    "0.20609573,0.71775756,0.37898585,0.66838395,0.02931972,0.63590036,\n",
    "0.03219793,0.74478066,0.472913,0.12175436])\n",
    "\n",
    "print('Sklearn MSE: {:.5f}. '.format(mean_squared_error(y_regression_true, y_regression_pred)))\n",
    "print('Your MSE: {:.5f}. '.format(own_mse(y_regression_true, y_regression_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn LogLoss: 1.10801\n",
      "Your LogLoss: 1.10801\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import log_loss from sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Define your own LogLoss function\n",
    "def own_logloss(y_true, prob_pred):\n",
    "  \t# Find loss for each observation\n",
    "    terms = y_true * np.log(prob_pred) + (1 - y_true) * np.log(1 - prob_pred)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(terms) \n",
    "    return -err\n",
    "\n",
    "y_classification_true = np.array([1,1,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,\n",
    "0,0,0,0,1,0,0,0,0,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,1,1,1,\n",
    "0,0,0,1,1,1,0,0,0,0,1,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0])\n",
    "\n",
    "y_classification_pred = np.array([0.2082483,0.4433677,0.71560128,0.41051979,0.19100696,0.96749431\n",
    ",0.65075037,0.86545985,0.02524236,0.26690581,0.5020711,0.06744864\n",
    ",0.99303326,0.2364624,0.37429218,0.21401191,0.10544587,0.23247979\n",
    ",0.30061014,0.63444227,0.28123478,0.36227676,0.00594284,0.36571913\n",
    ",0.53388598,0.16201584,0.59743311,0.29315247,0.63205049,0.02619661\n",
    ",0.88759346,0.01611863,0.12695803,0.77716246,0.04589523,0.71099869\n",
    ",0.97104614,0.87168293,0.71016165,0.95850974,0.42981334,0.87287891\n",
    ",0.35595767,0.92976365,0.14877766,0.94002901,0.8327162,0.84605484\n",
    ",0.12392301,0.5964869,0.01639248,0.72118437,0.00773751,0.08482228\n",
    ",0.22549841,0.87512453,0.36357632,0.53995994,0.56810321,0.22546336\n",
    ",0.57214677,0.6609518,0.29824539,0.41862686,0.45308892,0.93235066\n",
    ",0.58749375,0.94825237,0.55603475,0.50056142,0.00353221,0.48088904\n",
    ",0.927455,0.19836569,0.05209113,0.40677889,0.37239648,0.85715306\n",
    ",0.02661112,0.92014923,0.680903,0.90422599,0.60752907,0.81195331\n",
    ",0.33554387,0.34956623,0.38987423,0.75479708,0.36929117,0.24221981\n",
    ",0.93766836,0.90801108,0.34879732,0.63463807,0.27384221,0.20611513\n",
    ",0.33633953,0.32709989,0.8822761,0.82230381])\n",
    "\n",
    "print('Sklearn LogLoss: {:.5f}'.format(log_loss(y_classification_true, y_classification_pred)))\n",
    "print('Your LogLoss: {:.5f}'.format(own_logloss(y_classification_true, y_classification_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA statistics\n",
    "\n",
    "\n",
    "As mentioned in the slides, you'll work with New York City taxi fare prediction data. You'll start with finding some basic statistics about the data. Then you'll move forward to plot some dependencies and generate hypotheses on them.\n",
    "\n",
    "The train and test DataFrames are already available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (913000, 4)\n",
      "Test shape: (45000, 5)\n",
      "         date  store  item  sales\n",
      "0  2013-01-01      1     1     13\n",
      "1  2013-01-02      1     1     11\n",
      "2  2013-01-03      1     1     14\n",
      "3  2013-01-04      1     1     13\n",
      "4  2013-01-05      1     1     10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'fare_amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cc97f243947a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Describe the target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfare_amount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Train distribution of passengers within rides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'fare_amount'"
     ]
    }
   ],
   "source": [
    "# Shapes of train and test data\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "# Train head()\n",
    "print(train.head())\n",
    "\n",
    "# Describe the target variable\n",
    "print(train.fare_amount.describe())\n",
    "\n",
    "# Train distribution of passengers within rides\n",
    "print(train.passenger_count.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
